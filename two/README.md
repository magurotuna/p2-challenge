# Design question

各プロジェクトに割り当てた一意な `プロジェクトID` とそれに紐づく JavaScript のタグが、ユーザーのページに埋め込まれることによって、そのページへのアクセスやそのページで行われたイベント、ページからページの遷移などを検知し、アナリティクスシステムのバックエンドサーバに API を通して送信する、というような前提で考えていく。

バックエンドサーバは複数台用意し、ロードバランサを用いて適切に負荷分散することで、大量の API アクセスを捌くことができるように配慮を行う。  
負荷に応じて動的にスケーリングすることができるような設計とすることが望ましい（ AWS であれば `CloudWatch` 及び `AutoScaling` を使用する、など）（参考文献[1]）。  
バックエンドをアップデートしてリリースする場合には、ダウンタイムをゼロとするため、ブルー・グリーンデプロイをする。

API によってデータの提供を受けたバックエンドサーバは、そのデータをDBに格納する。大量の時系列データを高スループットで格納するため、 `Apache HBase` のような大規模データを扱うことを得意とする分散データベースを使用する。  
`HBase` やそれに関連する他の Apache フレームワーク（ `Spark` 、 `Hadoop` など）を使用することによって、大規模データをすばやく処理することができるのに加え、スケーラビリティも確保することができる。さらに、 `HBase` は高い可用性を実現していて、障害が発生しても高々数十秒のダウンタイムで復帰することが可能とされている（参考文献[2]）。  
AWS であれば `EMR` のようなサービスを使用することで、負荷に応じた自動スケーリングをすることができ、柔軟な運用が行える。

さらに、ユーザーが求めるメトリクスのうち特に頻繁に参照されるもの（例えば、ページビュー数の推移）などは、 `Apache Spark` などで処理を行った後、それを `Redis` 等でキャッシュすることによって、次回以降は `HBase` に負荷をかけずにユーザーにすばやく結果を提供できるようにする、といったキャッシュ戦略も効果的である。

最後に、時系列データを再処理したい場合に関しては、再処理にあたっては大量の時系列データを処理する必要があるため、 `Hadoop` のクラスタ数を増やす等して、処理能力を向上させた上で分散バッチ処理を行う、という方法が考えられる。

# 参考文献

1. https://aws.amazon.com/jp/cdp/cdp-autoscaling/
2. https://thinkit.co.jp/article/11963
